##### Day-1 [7-04-2025]

# Introduction to Pandas :

- It is the most important and **commonly used library in datascience domain**.
- Pandas is freeware and opensource.
- Pandas is built on top of Numpy.
- It allows fast analysis, data cleaning and preparation.
- **Perfoemace wise and productivity wise pandas is too good** to use.
- It can  work with data from a wide variety of sources like fies etc...
- By using pandas we can manipulate data very easily with very less code and in very less time.

>Note:
> - Numpy is a data analysis library.
> - Matplotlib is a data visualization library.
> - Pandas is **both data analysis and data visualization library**. Pandas data analysis is based on Numpy where as data visualization is based on matplotlib.

[Pandas website](https://pandas.pydata.org/)
Latest version: 2.2.3(Sep 20, 2024)

From Official Documentation:
- pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language.

How to install:
>		pip install pandas

How to check installation:
```py
>>> import pandas as pd
>>> pd.__version__ #'2.0.3'
```
Important Topics:
-------
- Series
- DataFrames
- Missing Data
- GroupBy
- Merging,Joining and Concatenating
- Operations
- Data input and output etc....

## Series :

- It is one of **key data structure** in pandas.
- It is **one-dimensional labeled arrays**. i.e a sequence of values associated with labels.

Creation of Series from python list:
----
```py
import pandas as pd
books_list = ['Python','Java','DataScience']
s = pd.Series(books_list)
print(type(s))
print(s)
```
>[!Note]
> 1. In the above Series object, we have 3-values (python,java,DS) associated with index labels (0,1,2), which are generated automatically by pandas.
> 2. For a string values, **dtype is considered as object**.
> 3. The **default index labels are integers starts from 0**. But we **can define any other type index labels** also.
> 4. The **index labels need not be unique**.
> 5. The Series can have **any type even hetrogenious** also.
> 6. Index labels and values need not be homogenious.

Ex:
```py
marks_list = [70,80,90]
s = pd.Series(marks_list)
print(s)
```
Ex:
```py
salaries_list = [1000.5,2000.6,3000.7]
s = pd.Series(salaries_list)
print(s)
```
Ex:
```py
hetro_list = [10,'Mahesh',10.5,True]
s = pd.Series(hetro_list)
print(s)
```


Creation of Series from python dict:
--------------
Ex-1
```py
books_dict = {0:'Python',1:'Django',2:'REST_API'}
s = pd.Series(books_dict)
print(s)
```
Ex-2
```py
books_dict = {'Book-1':'Python','Book-2':'Django','Book-3':'REST_API'}
s = pd.Series(books_dict)
print(s)
```

From Source code of pandas:
--------------------
```py
# Series class


# error: Cannot override final attribute "ndim" (previously declared in base
# class "NDFrame")
# error: Cannot override final attribute "size" (previously declared in base
# class "NDFrame")
# definition in base class "NDFrame"
class Series(base.IndexOpsMixin, NDFrame):  # type: ignore[misc]
    """
    One-dimensional ndarray with axis labels (including time series).

    Labels need not be unique but must be a hashable type. The object
    supports both integer- and label-based indexing and provides a host of
    methods for performing operations involving the index. Statistical
    methods from ndarray have been overridden to automatically exclude
    missing data (currently represented as NaN).

    Operations between Series (+, -, /, \\*, \\*\\*) align values based on their
    associated index values-- they need not be the same length. The result
    index will be the sorted union of the two indexes.

    Parameters
    ----------
    data : array-like, Iterable, dict, or scalar value
        Contains data stored in Series. If data is a dict, argument order is
        maintained.
    index : array-like or Index (1d)
        Values must be hashable and have the same length as `data`.
        Non-unique index values are allowed. Will default to
        RangeIndex (0, 1, 2, ..., n) if not provided. If data is dict-like
        and index is None, then the keys in the data are used as the index. If the
        index is not None, the resulting Series is reindexed with the index values.
    dtype : str, numpy.dtype, or ExtensionDtype, optional
        Data type for the output Series. If not specified, this will be
        inferred from `data`.
        See the :ref:`user guide <basics.dtypes>` for more usages.
    name : Hashable, default None
        The name to give to the Series.
    copy : bool, default False
        Copy input data. Only affects Series or 1d ndarray input. See examples.

    Notes
    -----
    Please reference the :ref:`User Guide <basics.series>` for more information.

    Examples
    --------
    Constructing Series from a dictionary with an Index specified

    >>> d = {'a': 1, 'b': 2, 'c': 3}
    >>> ser = pd.Series(data=d, index=['a', 'b', 'c'])
    >>> ser
    a   1
    b   2
    c   3
    dtype: int64

    The keys of the dictionary match with the Index values, hence the Index
    values have no effect.

    >>> d = {'a': 1, 'b': 2, 'c': 3}
    >>> ser = pd.Series(data=d, index=['x', 'y', 'z'])
    >>> ser
    x   NaN
    y   NaN
    z   NaN
    dtype: float64

    Note that the Index is first build with the keys from the dictionary.
    After this the Series is reindexed with the given Index values, hence we
    get all NaN as a result.

    Constructing Series from a list with `copy=False`.

    >>> r = [1, 2]
    >>> ser = pd.Series(r, copy=False)
    >>> ser.iloc[0] = 999
    >>> r
    [1, 2]
    >>> ser
    0    999
    1      2
    dtype: int64

    Due to input data type the Series has a `copy` of
    the original data even though `copy=False`, so
    the data is unchanged.

    Constructing Series from a 1d ndarray with `copy=False`.

    >>> r = np.array([1, 2])
    >>> ser = pd.Series(r, copy=False)
    >>> ser.iloc[0] = 999
    >>> r
    array([999,   2])
    >>> ser
    0    999
    1      2
    dtype: int64

    Due to input data type the Series has a `view` on
    the original data, so
    the data is changed as well.
    """
```
The 5 parameters of Series Constructor :
-----------------------
1. data parameter
2. index
3. dtype
4. name	
5. copy	

1).Data Parameter
----------
- data parameter can be used to represent data which is required to store inside Series object.
```py
books_dict = {'Book-1':'Python',10:20,10.5:20.6,'Book-2':'DS'}
s = pd.Series(data = books_dict)
print(s)
```

Ways to create Series / Valid Series creation :
```py
	s = pd.Series(data = [10,20,30])
	s = pd.Series(data = {0:'A',1:'B',2:'C'})
	s = pd.Series(data = {'A':'Apple','B':'Ball','C':'Cat'})
	s = pd.Series(data = np.array([10,20,30]))
	s = pd.Series(data = 10)
	s = pd.Series(data = 'Mahesh')
```
2).index parameter:
------------------
- We can use index parameter to **define our own index values**.
- The values need not be unique.
- If we are not using index, then pandas will generate **default index labels** which are integers starts from 0.
- The number of index values should be same as the number of values of data parameter.

Ex:
```py
name_list = ['Sunny','Bunny','Vinny']
s = pd.Series(data = name_list,index=['S','B','C'])
print(s)

# Note:
s = pd.Series(data = name_list,index=['S','B'])
#	ValueError: Length of values (3) does not match length of index (2)
```
Duplicate index labels possible.

```py
name_list = ['Sunny','Bunny','Vinny','Binny']
s = pd.Series(data = name_list,index=['S','B','C','B'])
print(s)
```
If the data is dict, then matched indexes only will be considered from the dict
```py
name_dict = {'S':'Sunny','B':'Bunny','V':'Vinny','C':'Chinny'}
s = pd.Series(data = name_dict,index=['S','B',])
print(s)
```
Ex:From pandas source code
```py
>>> d = {'a': 1, 'b': 2, 'c': 3}
>>> ser = pd.Series(data=d, index=['x', 'y', 'z'])
>>> ser
x   NaN
y   NaN
z   NaN
dtype: float64

#    Note that the Index is first build with the keys from the dictionary.
#    After this the Series is reindexed with the given Index values, hence we
#    get all NaN as a result.
```
##### Day-2 [8-04-2025]

RangeIndex:
------------------
- If we are not providing index parameter, then pandas will consider **default index values from RangeIndex(0,1,2,....n) object internally**.

Ex:
```py
name_list = ['Sunny','Bunny','Vinny','Chinny']
s = pd.Series(data = name_list)
print(s.index)#RangeIndex(start=0, stop=4, step=1)
```
Ex:
```py
name_list = ['Sunny','Bunny','Vinny','Chinny']
s = pd.Series(data = name_list)
s.index = pd.RangeIndex(start=10,stop=14,step=1)
print(s.index)
print(s)
```
Ex:
```py
s.index = pd.RangeIndex(start=10,stop=17,step=2)
print(s.index)
print(s)
```
3). dtype parameter :
-----------------
- We can use **dtype parameter to specify data type** for the output Series.

Ex:
```py
num_list = [10,20,30,40]
s1 = pd.Series(data=num_list,dtype='float')
s2 = pd.Series(data=num_list,dtype='bool')
s3 = pd.Series(data=num_list,dtype='str')
print(s1)
print(s2)
print(s3)
```
4). name parameter :
---------------
- We can assign name also to the Series. For this we have to use name parameter. The default name is None.
```py
num_list = [10,20,30,40]
s = pd.Series(data=num_list)
print(s.name)#None
```

```py
s = pd.Series(data=num_list,name='My Favourite Numbers')
print(s)

# We can also set name as:
s.name = 'My Numbers'
```
Setting name to the indexs:
-------------------------
```py
s.index.name = 'Default Indexes'
```
5). copy parameter :
-------------------
- This parameter decides whether it is required to create **View or Copy**.
- The default value is **False, i.e new object won't be created**.
- It is applicable only for **ndarray input**.

Ex-1: For list input
```py
num_list = [10,20]
s = pd.Series(data=num_list,copy=False)
s.iloc[0] = 333
print(s)
print(num_list)
# Even we changed Series content, that change not reflected to the list input.
```
Ex-2: For ndarray input
```py
arr = np.array([10,20])
s = pd.Series(data=arr,copy=False)
s.iloc[0] = 333
print(s)
print(arr)
# The changes of Series object reflected automatically inside ndarray input.

s = pd.Series(data=arr,copy=True)
# Even input is ndarray, separate copy got created because copy=True.
```
Exercise:
1. Create a python list named with student_list with 5 student names?
2. Create another python list named with marks_list with corresponding student marks?
3. Create a Series object that stores student marks as values and student names as index labels. Assign name 'Students' for this Series?


Sol:
```py
student_list = ['Sunny','Bunny','Vinny','Chinny','Pinny']
marks_list = [40,50,60,70,80]
ser = pd.Series(data=marks_list,index=student_list,name='Students')
print(ser)
```
4. Create a python dictionary with student_list and marks_list and create a Series object with that dictionary?
sol:
```py
student_list = ['Radhika','Bunny','Vinny','Chinny','Lilly']
marks_list = [40,50,60,70,80]
# ceate a dict combining two list
#students_dict = dict(zip(student_list,marks_list))
students_dict = {name:marks for name,marks in zip(student_list,marks_list)}
ser = pd.Series(data=students_dict,name='Students')
print(ser)
```
Accessing values from Series by using head() and tail() methods :
---------------
head():
-----

>Series.head(n=5)
> - Return the **first 'n' rows**. The default value for **n is 5**.
> - For **negative values of n**, this function **returns all rows except the last 'n' rows**.

Ex:
```py
import pandas as pd
s = pd.Series([i for i in range(50)])
print(s)
print(s.head())#Returns first 5 values
print(s.head(3))#Returns first 3 values
print(s.head(n=-46))#Returns the rows except last 46 rows. i.e first 4-rows.
```
tail()
----
> Series.tail(n=5)
> - Return the **last 'n' rows**. The default value for **n is 5**.
> - For **negative values of n**, this function **returns all rows except the first 'n' rows**.

```py
s = pd.Series([i for i in range(50)])
print(s.tail()) #Return last 5-rows
print(s.tail(3)) #Returns last 3-rows
print(s.tail(n=-3)) #Return all rows except first 3-rows
```
Q.Returns values from 10th to 15th by using head() and tail() methods?
```py
s = pd.Series([i for i in range(50)])
print(s.head(16).tail(6))
```
##### Day-3 [9-04-2025]

Extract values from Series by index position [index based selection]
------------------------------------------
Syn:
- s[x]
	- x can be index value
	- x can be list of indices
	- x can be slice also

Ex:
- s[5] ---> Returns values present at index 5
- s[[1,3,5]] ---> Returns Series of values present at indices 1,3 and 5
- s[2:6] ---> Returns Series of values from 2nd index to 5th index.

Ex: Series contains all upper case alphabet symbols as values
```py
# 1st way:
alphabets = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')
s = pd.Series(data=alphabets)
print(s)

# 2nd way:
from string import ascii_uppercase
alphabets = list(ascii_uppercase)
s = pd.Series(data=alphabets)
print(s)

# Q.To get first character?
s[0]

# Q.To get last character?
s[-1] #not supported
s[25]		or		s[s.size-1]

# Q.To get character present at 10th index position
s[10]

# Q.To get characters present at indices:5,10,15,20
s[[5,10,15,20]]

# Q.To get characters from 10th index to 16th index?
s[10:17]

# Q.To get every other character i.e every alternative character?
s[::2]

# Q.To get first 5 characters?
s[0:5] or s[:5]	or s.head() or s.head(5) or s.head(n=5)

# Q.To get last 3 characters?
s[-3:] or s[s.size-3:] or s.tail(3) or s.tail(n=3)

# Note:-ve indexing is applicable only for slice input.

s[-1]#Invalid
s[[-1,-2,-3]]#Invalid
s[-3:]#Valid

# Note:
	# Accessing based on position is applicable even for custom labeled Series also.
```
Extracting values from Series by labels [Label based selection] :
--------
Syn:
- s['label']
- s[['label-1','label-2','label-3']]
- s[label1:label3]

Sample code to append 'Label_' for every index:
---------------------------------------
Syn:
- map(function,sequence)
```py
alphabets = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')
#print(list(map(lambda x:'Label_'+x,alphabets)))
print(['Label_'+x for x in alphabets])
```
pandas inbuilt add_prefix() and add_suffix() methods :
----------------------------------------
```py
alphabets = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')
s = pd.Series(data=alphabets,index=alphabets)
#s = s.add_suffix('_Label')
s = s.add_prefix('Label_')
print(s)

# Q.To get first character?
s[0] or s['Label_A']

# Q.To get 10th character?
s[9] or s['Label_J']

# Q.To get values from 'Label_H' to 'Label_S'
s['Label_H':'Label_S']
```
> [!Note]
> 1. In the index based slicing, **end/stop attributes is not inclusive**.  
> s[2:5] - here 5 is not inclusive and it returns values from 2nd index to 4th index.
>
> 2. But in Lable based slicing, **end/stop attribute is inclusive**.  
> s['Label_H':'Label_S']  ---> 'Label_S' is inclusive.

Using dot notation to access data by labels:
-----------------------
Syn:
- s.label
- Returns the value associated with specified label

Ex:
```py
s.Label_Z #Z
```
Limitation: But this approach is **not applicable for index** and here we **cannot use slice operator**.

Ex:
```py
	s.0 #Invalid
	s.Label_A:Label_E #Invalid
```
Extracting values by using get() method
-----------------------------------------------------------
- In position based selection or label based selection, if the **specified index or label is not available then we will get an error**.
```py
s[100] #IndexError
s['Label_ZZ'] #KeyError: 'Label_ZZ'
```
- To overcome this problem we should **use get() method**.
- If the specified index or label is not available then we will get None but not error.

```py
print(s.get(100))#None
print(s.get('Label_ZZ'))#None
```
- Even in the case of get() method, we **can provide default value if the specified index or label is not available**.
```py
print(s.get(100,default='default value'))
print(s.get('Label_ZZ',default='default value'))
# Here default value will be considered because specified key and label are not available.
```


Ex:
```py
print(s.get(0))
print(s.get([0,3,7]))
print(s.get('Label_D'))
print(s.get(['Label_D','Label_G','Label_M']))
```
##### Day-4 [10-04-2025]

Extracting values by using loc and iloc indexers:
-------------------------------------
- loc indexer ---> For label based selection
- iloc indexer ---> For position based selection

- iloc ---> integer loc

iloc indexer:
---------
- For position based selection. The argument should be index.
Syn:
	- s.iloc[i]
	- s.iloc[[0,1,2]]
	- s.iloc[m:n]
Ex:
```py
import pandas as pd
s = pd.Series([10,20,30,40,50])
print(s)

# Q.To get first value?
s[0] or s.iloc[0]

# Q.To get values at indices:0,1,2
s.iloc[[0,1,2]]

# Q.To get the first 3 values
s.iloc[:3]

# Q.To get last value?
s[-1] #Invalid
s.iloc[-1] #Valid
```
loc indexer:
----------
- For label based selection.
Syn:
	- s.loc[label]
	- s.loc[[label1,label2,label3]]
	- s.loc[labelm:label:n]#here labeln is inclusive

Ex:
```py
alphabets = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')
s = pd.Series(data=alphabets,index=alphabets)
s = s.add_prefix('Label_')
print(s)

# Q.To get value associated with Label_A
s.loc['Label_A']
s.loc[0] #invalid

# Q.To get values associated with labels:Label_A, Label_K, and Label_Y
s.loc[['Label_A','Label_K','Label_Y']]

# Q.To get values from Label_H to Label_N?
s.loc['Label_H':'Label_N']

# Q.To get alternative values from Label_H to Label_N?
s.loc['Label_H':'Label_N':2]
```


Q.Assume 's' is the Series object, which of the following are valid syntactically?

1. s[0]
2. s['Label_A']
3. s.iloc[0]
4. s.iloc['Label_A']
5. s.loc[0]
6. s.loc['Label_A']

Ans: 1,2,3,6

>[!Note]
> 1. The main advantage of loc and iloc indexers when compared normal indexer is performance will be improved.
> 2. iloc and loc indexers are commonly used in dataframes.
> 3. In normal indexer we cannot pass negative index value. But in iloc indexer we can pass.
> 4. If we are depending on default indexes then there is no difference between loc and iloc indexers.
>
> Ex:
> ```py
> s = pd.Series([10,20,30,40,50])
> print(s[0])
> print(s.iloc[0])
> print(s.loc[0])
> ```
>
Boolean masking for condition based selection:
-----------------
- Condition based selection.
- We have to provide array of boolean values and selects from Series where True value present.
- It is applicable for normal **indexer, loc and iloc** indexers also.

- Syn:
	- s[[True,False,....]]
	- s.loc[[True,False,....]]
	- s.iloc[[True,False,....]]
	- s.get([True,False,.....])

Ex:
```py
s = pd.Series([10,20,30,40,50])
print(s[[True,False,False,True,True]])
print(s.loc[[True,False,False,True,True]])
print(s.iloc[[True,False,False,True,True]])
print(s.get([True,False,False,True,True]))
```
>[!Note]  
> The number of boolean values passed and the number of values in Series must be matched, otherwise we will get an error.
```py
s = pd.Series([10,20,30,40,50])
print(s[[True,False,False,True]])#IndexError: Boolean index has wrong length: 4 instead of 5
```
But in the case of get() method we wont get any error and just we will get None.
print(s.get([True,False,False,True]))#None

>[!Note]  
>	This approach is very helpful to get values based on some condition.
```py
# Ex-1:To select all values which are > 25
s = pd.Series([10,20,30,40,50])
print(s[s>25])

# Ex-2:To select values which are divisible by 3
print(s[s%3 == 0])
```
Usage of callables in Selecting elements:
----------------------------
- We can use callable object like function while selecting values from the Series.
- It should return anything, which should be valid argument for indexers and get method.

Ex:
```py
import pandas as pd
s = pd.Series([i for i in range(20)])

def odd_selections(s):
	return [True if i%2==1 else False for i in range(s.size)]

print(s[odd_selections])
```
We can pass callable object to **normal indexer, loc and iloc indexers and for get()** method also.

```py
import pandas as pd
s = pd.Series([i for i in range(20)])
print(s[lambda s:[True if i%2==1 else False for i in range(s.size)]])
print(s.loc[lambda s:[True if i%2==1 else False for i in range(s.size)]])
print(s.iloc[lambda s:[True if i%2==1 else False for i in range(s.size)]])
print(s.get(lambda s:[True if i%2==1 else False for i in range(s.size)]))
```
Summary: How to get values from Series object
------------------------------------
```py
1. s.head(n)
2. s.tail(n)
3. s[index]
4. s[[index1,index2,index3]]
5. s[indexm:indexn]#here indexn is not inclusive
6. s[label]
7. s[[label1,label2,label3]]
8. s[labelm:labeln]#here labeln is inclusive
9. s.iloc[index]
10. s.iloc[[index1,index2,index3]]
11. s.iloc[indexm:indexn]#here indexn is not inclusive
12. s.loc[label]
13. s.loc[[label1,label2,label3]]
14. s.loc[labelm:labeln]#here labeln is inclusive
15. s.get(index)
16. s.get([index1,index2,index3])
17. s.get(label)
18. s.get([label1,label2,label3])
```
- Even we can **provide boolean mask values and callable objects** as args.


##### Day-5 [12-04-2025]

## Attributes of Series object:
- Attributes are nothing but properties which providex information about the Series object.

1. values:
	- Returns values present inside Series object. Mostly it returns ndarray.
```py
import pandas as pd
s = pd.Series(data=['sunny','bunny','vinny','chinny','pinny','radhika'],
					index=[10,20,30,40,50,60])
print(s.index)
```
2. index:
	- Returns the index(axis labels) of the Series
	```py
	print(s.index)
	```

3. dtype:
	- Returns the dtype object of the underlying data
	```py
	print(s.dtype)
	```

4. size:
	- Returns the number of elements present in the Series object.
	```py
	print(s.size)
	```
5. shape:
	- Returns a tuple of the shape of the underlying data.
	- In the case of Seies, it is single valued tuple, which represents the number of elements present in the Series object.
	```py
	print(s.shape)
	```

6. ndim:
	- Returns number of dimensions of the underlying data, by definition 1
	```py
	print(s.ndim)
	```
7. name:
	- Returns the name of the Series. Default name is None
	```py
	print(s.name)
	```
8. is_unique:
	- Returns True if values in the object are unique.
	```py
	s = pd.Series(data=['sunny','bunny','vinny',])
	print(s.is_unique)#True
	s = pd.Series(data=['sunny','bunny','sunny'])
	print(s.is_unique)#False
	```
>[!Note]  
> - To get number of unique values, we can use nunique() method
> - Bydefault it ignores(drops) NaN values.
> - If we want to consider NaN values also then we have to use dropna=False.
>		- Series.nunique(dropna=False)
>
>Ex:
> ```py
> s = pd.Series(data=['sunny','bunny','vinny','chinny','pinny','sunny','chinny',np.NaN])
> print('The number of unique values with NaN ignore:'s.nunique())#5
> print('The number of unique values without NaN ignore:'s.nunique(dropna=False))#6
> ```
>
9. is_monotonic:
	- monotonic means whether values are in some order.

- is_monotonic_increasing ==> Returns True if values in the object are **increasing order**.
- is_monotonic_decreasing ==> Returns True if values in the object are **decreasing order**.

	```py
	s1 = pd.Series([10,20,30,40])
	s2 = pd.Series([40,30,20,10])
	print(s1.is_monotonic_increasing)#True
	print(s1.is_monotonic_decreasing)#False
	print(s2.is_monotonic_increasing)#False
	print(s2.is_monotonic_decreasing)#True
	```
10. hasnans:
	- Returns True if Series contains NaN or None.
	- i.e we can use this attribute to check whether some values are absent/missing or not.
	```py
	s1 = pd.Series([10,20,30])
	s2 = pd.Series([40,30,pd.NA])
	s3 = pd.Series([10,20,30,None])
	print(s1.hasnans)#False
	print(s2.hasnans)#True
	print(s3.hasnans)#True
	```
Summary:
-------
1. values
2. index
3. dtype
4. size
5. shape
6. ndim
7. name
8. is_unique/nunique()
9. is_monotonic_increasing/is_monotonic_decreasing
10. hasnans

Passing Series object to the python's inbuilt functions.
-------------------------------
1. len(s):
	- Retruns the number of elements present in the Series object.

2. type(s):
	- It returns the type of Series object. <class 'pandas.core.series.Series'>

3. dir(s):
	- Returns a list of all members(variables and methods) which are applicable for Series object.

4. sorted(s):
	- It will sort the elements present in the Series object and returns list of those values.

5. list(s):
	- To get Series object values in the form of list.It is Series to list conversion.
	- List contains only values but not index labels.

6. dict(s):
	- To convert Series object to dictionary
	- dict keys ----> Series object index labels
	- dict values ----> Series object values

7. max(s):
	- Returns max values present in Series object.

8. min(s):
	- Returns min values present in Series object.

Ex:
```py
import pandas as pd
s = pd.Series([10,40,20,30])
print(s)
print(len(s))
print(type(s))
print(dir(s))
print(sorted(s))
print(list(s))
print(dict(s))
print(max(s))
print(min(s))
```
Q.What is the main difference between pandas Series object and pythons dict object?

- In the case of pandas Series object, duplicate index labels(keys) are possible. 
- But in the case of python dict, duplicate keys are not possible.

- Whenever we are trying to convert Series object to python dict, if duplicate index labels are there, then with those duplicate index labels and values, a Series object will be created and assign that Series object to the corresponding key in the dictionary. The advantage of this approach is, we are not missing any data in the conversion from the Series object to dict.

Ex:
```py
import pandas as pd
s = pd.Series(data=['sunny','bunny','vinny','chinny','pinny'],index=[10,20,30,40,10])
print(s)
d = dict(s)
print(d)
print(type(d[10]))
```
Note:
```py
d = dict(s)
for k,v in d.items():
	print(f'{k}--->{type(v)}')
```

##### Day-6 [15-04-2025]

## Creation of Series object with the data from the csv file

- We know already the creation of Series object from list,dict, ndarray and scalar values.
- We can create Series object with the data from multiple sources like csv file, excel file, json file, html file etc...

- Pandas contains multiple functions for this like:
	- pd.read_csv()
	- pd.read_excel()
	- pd.read_html()
	- pd.read_json()

Ex:
```py
import pandas as pd
df = pd.read_csv('student.csv')
print(type(df))#<class 'pandas.core.frame.DataFrame'>
print(df)
```
>[!Note]
> - read_csv() : function returns DataFrame object bydefault but not Series object.
> - If data contains only one column, then we can get Series object by using squeeze() function.

```py
s= pd.read_csv('student.csv',usecols=['Name of Student'])
print(type(s))
s1 = s['Name of Student'].squeeze()
print(type(s1))
print(s1)
```
The importance of count() method:
----------
```py
Series.count():
	Returns the number of non-NA/null observations in the Series.
```
>[!Note]
> - In the csv file ---> blank/null/NaN/nan is always treated as NaN, But **None is not treated as NaN**.
> - But from python list ---> **None is also treated as missing data**.

Ex:
```py
s= pd.read_csv('student.csv',
		usecols=['Name of Student','Marks'],
		index_col = 'Name of Student')
print(type(s))
s1 = s['Marks'].squeeze()
print(type(s1))
print(s1.size)
print(s1.count())
```
Ex:
```py
s = pd.Series([10,20,30,None,pd.NA,np.nan])
print(s)
print('Size:',s.size)
print('Count',s.count())
```
size attribute vs count() method:
--------------
- size attribute returns the number of values including **NAs and null values**.
- But count() method returns number of **non-NA/null observations** in the Series.

Handling NAs [isnull() / isna() ]:
---------------------
isnull()/isna() method
```py
Series.isnull():
		Detect missing values.

# Return a boolean same-sized object indicating if the values are NA.
# NA values, such as None or numpy.NaN, gets mapped to True values.
# Everything else gets mapped to False values. 
```
Ex:
```py
s = pd.Series([10,20,30,None,pd.NA,np.nan])
s1 = s.isnull()
print(s1)
```
To get only missing data:
------------
```py
s = pd.Series([10,20,30,None,pd.NA,np.nan])
s1 = s[s.isnull()]
print(s1)

# Note:
# s.isnull() returns boolean Series object, which is used for boolean masking to select only where NA is available.
```
Ex:
```py
df= pd.read_csv('student.csv',
		usecols=['Name of Student','Marks'],
		index_col = 'Name of Student')
#To get data where values are missing
s = df['Marks'].squeeze()
print(s)
s1 = s[s.isnull()]
print(s1)

# Note: s.isna() is just alias name for s.isnull(). Hence we can use these two methods interchangeably.
```
How to get the number of missing values:
------------------
- 1st way: s.size - s.count()
- 2nd way: s.isnull().sum()
- 3rd way: s[s.isnull()].size

Note: While performing sum() operation, False is treated as 0 and True is treated as 1

notnull()/notna()
----------
```py
s.notna()
# 		Detect existing (non-missing) values.
# Return a boolean same-sized object indicating if the values are not NA.
# Non-missing values get mapped to True. Missing values are mapped to False.

# Note: s.notna() is alias for s.notnull()
```
To get non-missing values
```py
print(s[s.notnull()])
print('The number of values:',s[s.notna()].size)
```
Questions:

- Q1. How to check whether Series object contains NaN/null values or not?
	- By using hasnans attribute
	- print(s.hasnans)#True

- Q2. How to get only missing values?
	- s[s.isnull()]		or		s.loc[s.isnull()]
	- s[s.isna()]		or		s.loc[s.isna()]

- Q3.How to get number of missing values?
	- s.size-s.count()
	- s.isnull().sum()
	- s[s.isnull()].size

- Q4.How to get non-missing values?
	- s[s.notnull()]		or		s.loc[s.notnull()]
	- s[s.notna()]		or		s.loc[s.notna()]

- Q5.How to get number of non-missing values?
	- s.notnull().sum()	or		s.notna().sum()
	- s[s.notnull()].size	or		s[s.notna()].size
	- s.count()

- Q6.Which of the following expression returns True?
	- A. s.size == s.isnull().sum() + s.notnull().sum()
	- B. s.count() == s.isnull().sum() + s.notnull().sum()
Ans:A

How to drop NAs?
----------------
```py
Series.dropna():
	Return a new Series with missing values removed. Because of this method there is no changes in the existing Series object.
```
Ex:
```py
s1 = s.dropna()
print(s1)
# Note : In the above example, still s contains NAs because dropna() method returns a new Series object.
```
How to drop NAs in the existing object only
----------------
- We have to set inplace parameter with True value. The default value is False.
```py
s.dropna(inplace=True)
print(s)
```
How to replace NAs with our required value?
------------------------
- By using fillna()
```py
s1 = s.fillna(0)
print(s1)
```
To perform modification in the existing object only
--------------------
```py
s.fillna(0,inplace=True)
print(s)
```

##### Day-7 [16-04-2025]

## Basic statistics for Series object:
1. sum():
	- Returns the sum of values, present inside Series object.
	- This method ignores NAs automatically.

2. mean():
	- Mean means average
	- Returns mean value of the Series.
	- s.mean()
	- s.sum()/s.count()

3. median():
	- It returns middle element in the sorted list of values
	- Number of values odd:returns middle value
	- 1,2,3,4,5,6,7 --->median is:4
	- Number of values are even:returns mean of middle 2-values
	- 1,2,3,4,5,6,7,8 --->median is 4.5(mean of 4 and 5)

4. var():
	- Returns the variance of values of the Series object.

5. std():
	- Returns the standard deviation of values of Series object
	- It is the square root of variance.

6. mode():
	- Returns the most repeated value. i.e most frequently occurred value.

Q.How to find the number of times value repeated?
```py
import pandas as pd
df= pd.read_csv('student.csv',
		usecols=['Name of Student','Marks'],
		index_col = 'Name of Student')
s = df['Marks'].squeeze()
print(s)
print('The sum of all values:',s.sum())
print('The mean value:',s.mean())
print('The mean value:',s.sum()/s.count())
print('The median value:',s.median())
print('The variance value:',s.var())
print('The standard deviation:',s.std())
print(int(s.std()**2) == int(s.var()))
print('The mode:',s.mode())
print('The number of times mode value repeated:',s[s==400].size)
print('The number of times mode value repeated:',s[s==s.mode()[0]].size)
```
7. min() and max():
	- Returns minimum and maximum value present in the Series

The importance of describe() method:
----------------
- It generates descriptive statistics like **count,mean,std,min,max** etc...
- Before analyzing our data, it is recommended to use this method to get descriptive statistics about our Series object.
```py 
print(s.describe())
```

Exercise:
-------
1. Separate non-nulls from the student Series, which is generated from student.csv file, and assign this Series to existing_marks variable?
2. Find sum of all student marks?
3. Find the students whose marks >= 500?
4. Find the sum of all students marks which are >= 500?
5. How many students got marks < 350?
6. How many students got marks >= 400?
7. Find highest marks in Series?
8. Find least marks in the Series?

sol:
```py
import pandas as pd
df= pd.read_csv('student.csv',
		usecols=['Name of Student','Marks'],
		index_col = 'Name of Student')
students = df['Marks'].squeeze()
print(students)
existing_marks = students[students.notnull()]
print(existing_marks)
print('The sum of all student marks:',existing_marks.sum())
print(existing_marks[existing_marks >= 500])
print(existing_marks[existing_marks >= 500].sum())
print('The number of students whose marks < 350:',
								existing_marks[existing_marks < 350].size)
print('The number of students whose marks >= 400:',
								existing_marks[existing_marks >= 400].size)
print('Highest marks:',existing_marks.max())
print('Least marks:',existing_marks.min())
```
Finding index labels associated with maxvalue and minvalue:
---------------
without using readymade methods:

- s.max() --> Returns max value
- s[s==s.max()] --> Returns Series object, where max value available
- s[s==s.max()].index --> Returns Index object
- s[s==s.max()].index[0] --> Returns index label which is associated with max value.

We can do the same thing directly by using ready made methods: **idxmax() and idxmin()**

```py
print(s.idxmax())
print(s.idxmin())
```
Finding first n largest and n smallest values:
-----------------------
```py
print(s.nlargest(n=3))
print(s.nsmallest(n=3))
```
Sorting of values by using sort_values() method:
---------------------
This method is helpful to **sort only based on values** but not based on index labels.

- Syn:
	- Series.sort_values(ascending=True, inplace=False, kind='quicksort', na_position='last')

Ex:
```py
s.sort_values(inplace=True,na_position='first',ascending=False)
print(s)
```
Sorting based on index labels by using sort_index() method:
------------------
```py
s.sort_index(inplace=True,na_position='first',ascending=True)
print(s)
```
## Basic Arithmetic operations for Series object:

1. Arithmetic operations with scalar value:
- Scalar means constant value
- We can perform arithmetic operations between Series object and scalar value.
- Operation will be performed for every element.

Ex:
```py
import pandas as pd
s = pd.Series([10,20,30,40,50])
print(s)
print(s+10)
print(s-3)
print(s*3)
print(s/2)
```
>[!Note]
> - If the value is NA, then after performing scalar operations the result is always NA only.

```pt
import pandas as pd
import numpy as np
s = pd.Series([10,pd.NA,np.NaN,None])
print(s)
print(s+10)
```
##### Day-8 [17-04-2025]

2. Arithmetic operations between 2-Series objects:
- These operations will be performed only on matched indexes.
- For unmatched indexes, NaN will be returned.

Ex:
```py
import pandas as pd
s1 = pd.Series([10,20,30])
s2 = pd.Series([10,20,30])
print(s1+s2)
```
Ex:
```py
s1 = pd.Series(data = [10,20,30,40,50],index = ['A','B','C','D','E'])
s2 = pd.Series(data = [10,20,30,40,50],index = ['C','D','E','F','G'])
print(s1+s2)
```
>[!Note:
> - Series class contains equivalant methods for arithmetic operations
>	- s1+s2 ----> s1.add(s2)
>	- s1-s2 ----> s1.sub(s2)
>	- s1*s2 ----> s1.mul(s2)
>	- s1/s2 ----> s1.div(s2)

fill_value parameter:
-----------------
- We can pass fill_value parameter for add(),sub(),mul() and div() methods.
- If the **matched index is not available**, then **fill_value will be considered in the place of missing element**.
- fill_value parameter is the advantage of add()/sub()/mul()/div() methods when compared with +,-,*,/ operators.

Ex:
```py
s1 = pd.Series(data = [10,20,30,40,50],index = ['A','B','C','D','E'])
s2 = pd.Series(data = [10,20,30,40,50],index = ['C','D','E','F','G'])
print(s1.add(s2,fill_value=0))
```
Ex:
```py
s1 = pd.Series(data = [10,np.NaN],index = ['A','Z'])
s2 = pd.Series(data = [10,20],index = ['A','B'])
print(s1.add(s2,fill_value=0))
```
Cumulative operations / Progressive operations:
--------------------------------
sum() and cumsum()
---
1. sum()--->To find the sum of all values
2. cumsum()---> Returns a Series of the same size containing the cumulative sum

Ex:
```py
s = pd.Series([10,20,30,40,50])
print(s.sum())
print(s.cumsum())
```
>[!Note]
> - Bydefault cumsum() method ignores NAs while performing cumulative sum operation.
> - By using skipna parameter we can customize this behaviour.
> - The default value is True.

Ex:
```py
s = pd.Series([pd.NA,10,20,30,40,50])
print(s.sum())
print(s.cumsum())
```
Ex:
```py
s = pd.Series([pd.NA,10,20,30,40,50])
print(s.sum())
print(s.cumsum(skipna=False))
```
prod() and cumprod()
---------------
```py
s = pd.Series(data = [1,2,3,4,5])
print(s.prod())
print(s.cumprod())
```
min() and cummin()
---------------
```py
s = pd.Series(data = [1,2,3,4,5])
print(s.min())
print(s.cummin())
```
max() and cummax()
----------------
```py
s = pd.Series(data = [1,2,3,4,5])
print(s.max())
print(s.cummax())
```
Finding Discrete Difference by using diff() method:
-----------------------------------
Series.diff(periods=1)

- First discrete difference of element
- Calculate the difference of a Series element compared with another element in the Series(default element is previous row)
```py
s = pd.Series(data = [10,20,30,40,50])
print(s.diff())#s.diff(periods=1)
```


	i1--->v1
	i2--->v2
	i3--->v3
	i4--->v4
	i5--->v5

	periods=1
	----------
	i1--->v1-NaN
	i2--->v2-v1
	i3--->v3-v2
	i4--->v4-v3
	i5--->v5-v4

	periods=2 (difference with 2nd previous element)
	----------------------------------------------
	i1--->v1-NaN
	i2--->v2-NaN
	i3--->v3-v1
	i4--->v4-v2
	i5--->v5-v3

	periods=-1 (difference with next element)
	---------------------------------------
	i1--->v1-v2
	i2--->v2-v3
	i3--->v3-v4
	i4--->v4-45
	i5--->v5-NaN

>[!Note]
>- This diff() method is very helpful while working with Time Series in DataScience.

Filtering elements of Series based on values:
-----------------------------------
- By using boolean masking or callable functions, we can filter elements.

Ex:
```py
import pandas as pd
df= pd.read_csv('student.csv',
		usecols=['Name of Student','Marks'],
		index_col = 'Name of Student')
s = df['Marks'].squeeze()
print(s)
print(s[s<500])#Boolean masking
print(s.loc[s<300])#Boolean masking

def lt_700(x):
	return x < 700

print(s[lt_700])#passing callable object
```
Note:
- In the above example filtering happened based on values but not based on index labels.
- If we want to filter elements based on index labels then we should go for **filter() method**.

Filtering elements of Series based on index labels by using filter()
-------------------------------------------------------
- Series.filter(items=None, like=None, regex=None, axis=None)

Q. To select rows of Series where index labels are starts with 'S'
```py
print(s.filter(regex='^S'))
```
Q. To display rows ends with 'y
```py
print(s.filter(regex='y$'))
```
Q. To display starts with 'A' or 'B'
```py
print(s.filter(regex='^[AB]'))
```
Q. To display rows contains 'nn'
```py
print(s.filter(like='nn'))
```

##### Day-9 [18-04-2025]

Replacing elements of Series by using where() method
-----------------------------
- It is counter part of mask() method
```py
Syn:
	Series.where(cond, other=nan, *, inplace=False, axis=None, level=None)

# - it returns a new Series with the values
# - Replace values where the condition is False with the other parameter value.
# - if condition is true, Then replacement won't be happened.
# - By using other parameter we can provide new value.
```
Ex: Replacing values as 'Falied' where marks < 300?
```py
s1 = s.where(lambda x: x > 300,other='Failed')
print(s1)
```
Replacing elements of Series by using mask() method
```py
Syn:
	Series.mask(cond, other=<no_default>, *, inplace=False, axis=None, level=None)

Replace values where the condition is True.
```
Ex: Replace values as 'Failed' where marks < 300?
```py
s1 = s.mask(lambda x:x < 300,other='Failed')
print(s1)
```
Ex:Replace values as first class where marks > 500?
```
s1 = s.mask(lambda x:x > 500,other='First Class')
print(s1)
```
>[!Note]
> - mask() replaces value if conditin is True.
> - where() replaces value if the condition is False.

## Transforming Series object:

- Transforming means updating values of Series object
- There are 2-types of transformations
	1. Partial Transformation
	2. Global/Full Transformation

1.Partial Transformation:
----------
- A subset of records will be updated but not all.
- We can perform this operation by using **update() method**.

2.Global/Full Transformation:
---------
- It wil update full set of records/all records.
- We can perform this operation by using either **map() or apply() methods**.

Tranforming Series object by using update() method
----------------------------------------

- We can update a particular element by using normal indexing or loc/iloc indexers.

Ex:
```py
import pandas as pd
s = pd.Series([10,20,30,40])
s[0] = 100
s.loc[3] = 300
print(s)
```
- In the above program, to update n elements, we have to use n lines of code.
- To perform this operation in a simple way, we should go for update() method.
```py
s.update(pd.Series([200,400],index=[0,3]))
print(s)
```
```py
Syn:
	Series.update(other)

# Modify Series in place using values from passed Series.
# Uses non-NA values from passed Series to make updates. Aligns on index.

# Parameters
# otherSeries, or object coercible into Series like list or dict etc...
```
Ex:
```py
s = pd.Series([1, 2, 3])
s.update(pd.Series([4, 5, 6]))
print(s)
0    4
1    5
2    6
dtype: int64
```
Ex:
```py
s = pd.Series(['a', 'b', 'c'])
s.update(pd.Series(['d', 'e'], index=[0, 2]))
s
0    d
1    b
2    e
dtype: object
```
Ex:
```py
s = pd.Series([1, 2, 3])
s.update(pd.Series([4, 5, 6, 7, 8])) #Extra elements will be ignored.
s
0    4
1    5
2    6
dtype: int64

# Note:
# If other/argument contains NaNs the corresponding values are not updated in the original Series.

s = pd.Series([1, 2, 3])
s.update(pd.Series([4, np.nan, 6]))
s
0    4
1    2
2    6
dtype: int64

# Note:
# Other can also be a non-Series object type like list or dict, that is convercible into a Series.


s = pd.Series([1, 2, 3])
s.update([4, np.nan, 6])
s
0    4
1    2
2    6
dtype: int64

s = pd.Series([1, 2, 3])
s.update({1: 9})
s
0    1
1    9
2    3
dtype: int64
```
Some one is asking in interview:
----------------
Ex:
```py
s1 = pd.Series([1,2,3,4],index=[1,2,3,4])
s2 = pd.Series([5,6,7,8],index=['a','b','c','d'])
s1.update(s2)
print(s1)

# s1 has an index of [1, 2, 3, 4].
# s2 has an index of ['a', 'b', 'c', 'd']. 
# When call s1.update(s2), pandas looks for matching index labels between s1 and s2.
# Because the indices are completely different (integer-based vs. string-based),
# there are no overlapping labels. With no matches found, no updates are performed, and s1 remains unchanged.

```
- The output will be the original series s1 with no changes.

##### Day-10 [19-04-2025]

# Introduction to DataFrame:

- Dataframe is a labeled 2-D array. It contains multiple rows and columns.

Ex:
```py
import pandas as pd
enos = [100,200,300,400]
enames = ['Sunny','Bunny','Vinny','Chinny']
esals = [1000,2000,3000,4000]
eaddrs = ['Hyd','Bng','Chennai','Mumbai']
df = pd.DataFrame({'eno':enos,'ename':enames,'esal':esals,'eaddr':eaddrs})
print(df)
print(df.ndim)#2
print(df.shape)#(4,4)
print(df.ename)
print(type(df.ename))#<class 'pandas.core.series.Series'>
```
Conclusions:

1. Series is a labled 1-D array where as DataFrame is alabled 2-D array.
2. Each column of DataFrame as Series. Hence we can consider Dataframe is nothing but a collection of Series object.
```py
Note:
	print(df.dtype)#Error
	print(df.dtypes)#Valid
```
3. Series object holds only homogenious values. But DataFrame contains multiple columns and each column value may be of different types. Hence dataframe holds heterogeneous data.

## Various ways of create DataFrame object:

1. From the dict of list objects

2. From dict of tuple objects
- Instead of list objects, we can use tuple objects
	```py
	enos = (100,200)
	enames = ('Sunny','Bunny')
	esals = (1000.0,2000.0)
	eaddrs = ('Hyd','Bng')
	df = pd.DataFrame({'eno':enos,'ename':enames,'esal':esals,'eaddr':eaddrs})
	print(df)
	```
3. From dict of Series objects
	```py
	enos = pd.Series([111,222])
	enames = pd.Series(['Katrina','Kareena'])
	esals = pd.Series([3333.0,6666.0])
	eaddrs = pd.Series(['Hyd','Bng'])
	df = pd.DataFrame({'eno':enos,'ename':enames,'esal':esals,'eaddr':eaddrs})
	print(df)
	```
4. From dict of dicts:
	```py
	df = pd.DataFrame({'eno':{0:100,1:200},'ename':{0:'Radhika',1:'Lilly'},
	'esal':{0:1000,1:2000},'eaddr':{0:'Hyd',1:'Bng'}})
	print(df)
	```

#### Note using enumurate and creating a dictionary using list
Ex:
l = [10,20,30,40]
for k,v in enumerate(l):
	print(k,v)

Ex: # creating disct using list.
l = [10,20,30,40]
def build_dict(l):
	d = {k:v for k,v in enumerate(l)}
	return d
print(build_dict(l))

Instead of hard coding values we can build dict dynamically
```py
enos = [100,200]
enames = ['Sunny','Bunny']
esals = [1000,2000]
eaddrs = ['Hyd','Bng']

def build_dict(l):
	d = {k:v for k,v in enumerate(l)}
	return d

df = pd.DataFrame({'eno':build_dict(enos),'ename':build_dict(enames),
'esal':build_dict(esals),'eaddr':build_dict(eaddrs)})
print(df)
```
5. From list of dicts

- Here we can provide data row-wise
	```py
	df = pd.DataFrame([{'eno':101,'ename':'Katrina','esal':10000,'eaddr':'Mumbai'},
	{'eno':102,'ename':'Kareena','esal':15000,'eaddr':'Bng'}])
	print(df)
	```
- without hardcoding data  
	```py
	enos = [100,200]
	enames = ['Sunny','Bunny']
	esals = [1000,2000]
	eaddrs = ['Hyd','Bng']

	row_wise_data =  [{'eno':eno,'ename':ename,'esal':esal,'eaddr':eaddr} for eno,ename,esal,eaddr in zip(enos,enames,esals,eaddrs)]
	#print(row_wise_data)
	df = pd.DataFrame(row_wise_data)
	print(df)
	```
6. From numpy ndarray
	```py
	import pandas as pd
	import numpy as np
	df = pd.DataFrame(np.array([[1,2,3],[4,5,6],[7,8,9]]),columns=['a','b','c'])
	print(df)
	```
Note:  
Most of **methods and attributes of Series are applicable for DataFrame also**.

Ex:
```py
import pandas as pd
df = pd.read_csv('student.csv')
print(df.head(n=3))
print(df.tail(n=3))
print(df.shape)
print(df.ndim)
print(df.index)
print(df.values) #List of list object, each inner list represents one row.
```


##### Day-11 [22-04-2025]

The importance of info() method:
-----------
- It generates summary information of DataFrame. Before using DataFrame, it is highly recommended to use this method.
```py
Syn:
		DataFrame.info(verbose=None, buf=None, max_cols=None,
		memory_usage=None, show_counts=None)
```
- Print a concise summary of a DataFrame.
- This method prints information about a DataFrame including the **index dtype and columns, non-null values and memory usage**.

Ex:
```py
import pandas as pd
df = pd.read_csv('student.csv')
print(df.info())
```
verbose parameter:
- Whether to print the full summary or not. i.e column names in table form. Bydefault it will print.
```py
print(df.info(verbose=False))
```
The importance of sample() method
---------------------
- We can use sample() method to get random record from DataFrame.
```py
# Syn
DataFrame.sample(n=None, frac=None, replace=False, weights=None, random_state=None, axis=None, ignore_index=False)
```
```py
df = pd.read_csv('student.csv')
print(df.sample())

To get multiple random records we have to use 'n' parameter.
print(df.sample(n=3))

To get specific fraction of records from total
frac means fraction
df.sample(frac=0.1)#To get 10% of total records
df.sample(frac=0.5)#To get 50% of total records
```
Q. Diff b/w:
- df.head(n=3) ==> **Returns first 3-records**
- df.sample(n=3) ==> **Returns 3-random records**

How to select only one required column from DataFrame?
---------------------------
- 1st way: df.column_name
- 2nd way: df['column_name']

- both methods returns Series object

- 2nd way recommended because column name contains spaces like 'First Name'
	- df.First Name==>Invalid
	- df['First Name']==>Valid

Ex:
```py
import pandas as pd
df = pd.read_csv('emp.csv')
print(df.ENAME)
print(df['ENAME'])
```
How to select multiple columns from Dataframe
------------------------------------
- df[[list of required columns]]:Returned DF with required columns.
```py
df = pd.read_csv('emp.csv')
required_columns = ['ENAME','EADDR']
print(df[required_columns])
```
## Casestudy:

sample_numbers.csv

1). Write code to select only C4 column?
```py
df = pd.read_csv('sample_numbers.csv')
print(df['C4'])
```
2). Write a code to select only c2 and c4 column data?
```py
print(df[['C2','C4']])
```
3). Write code to select from C2 to C4 columns data but in reverse order(i.e C5,C4,C3,C2)
```py
print(df[['C5','C4','C3','C2']])
```
## Arithmetic operations for DF:
- We **cannot apply arithmetic operations directly on DataFrame object** because it contains multiple columns.
- But we can perform arithmetic operations by **selecting a particular column of the DF**, because each column of a DF is a Series object.

Ex:
```py
df = pd.read_csv('emp.csv')
#print(df['ESAL']+500)
print(df['ESAL'].add(800))
print(df['ESAL'].sub(800))
print(df['ESAL'].mul(800))
print(df['ESAL'].div(800))
```
Adding a new column to DataFrame:
---------------------------------
1. 1st way:
```py
df['column'] = value
```
- The value can be **either a single value or Series object**.
- If the **specified column is already available** then every value will be **replaced with new provided value**.
- If the **specified column is not available** then as new column will be added to the DF with provided values.
- The new column will be **added at last**.
```py
df = pd.read_csv('emp.csv')
print(df)
print('-'*33)
df['ESAL'] = 3333
df['COUNTRY'] = 'India'
print(df)

df['COUNTRY'] = ['India','UK','US','AUS','CANADA']
```
2. 2nd way:By using insert() method

- The advantage of insert() method is we can insert column at our required location.
```py
DataFrame.insert(loc, column, value, allow_duplicates=<no_default>)

# Insert column into DataFrame at specified location.
# Raises a ValueError if column is already contained in the DataFrame, unless allow_duplicates is set to True.
```
Ex:
```py
df.insert(a,'ESAL',3333)
ValueError: cannot insert ESAL, already exists
```
Ex:
```py
df.insert(1,'COUNTRY',['IND','US','UK','AUS','CANADA'])
print(df)
```
How to drop DF rows with missing values / null values?

- We have to use **dropna()** method.
```py
DataFrame.dropna(*, axis=0, how=<no_default>, thresh=<no_default>, subset=None, inplace=False, ignore_index=False)

# Bydefault it removes rows from the DF where row contains atleast one missing value.
```
ex:
```py
df = pd.read_csv('emp.csv')
print(df)
print('-'*33)
df1 = df.dropna()
print(df1)
```
'how' parameter:
---------
- how{'any', 'all'}, default any
- Determine if row or column is removed from DataFrame, when we have at least one NA or all NA.

- 'any' : If any NA values are present, drop that row or column.
- 'all' : If all values are NA, drop that row or column.
```py
df1 = df.dropna(how='any')
print(df1)

df1 = df.dropna(how='all')
print(df1)
```
inplace parameter:
----------
```py
df.dropna(inplace=True)
print(df)
```
